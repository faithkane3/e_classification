{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# visualize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(11, 9))\n",
    "plt.rc('font', size=13)\n",
    "\n",
    "# turn off pink warning boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# acquire\n",
    "from env import host, user, password\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove limegreen; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire\n",
    "\n",
    "**<font color=green>A Few Example Methods for Reading Data into Pandas DataFrames</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove limegreen; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a Database\n",
    "\n",
    "Create your DataFrame using a SQL query to access a database.\n",
    "\n",
    "**<font color=purple>Use your env file info and create your sql query and create connection_url for use in pandas `read_sql()` function.</font>**\n",
    "\n",
    "```python\n",
    "# Import private info to keep it secret in public files.\n",
    "from env import host, password, user\n",
    "\n",
    "# Test query in Sequel Pro and save to a variable.\n",
    "sql_query = 'write your sql query here; test it in Sequel Pro first!'\n",
    "\n",
    "# Save connection url to a variable for use with pandas `read_sql()` function.\n",
    "connection_url = f'mysql+pymysql://{user}:{password}@{host}/{'database_name'}'\n",
    "    \n",
    "# Python function to read data from database into a DataFrame.\n",
    "pd.read_sql(sql_query, connection_url)\n",
    "```\n",
    "\n",
    "**<font color=purple>Put it all together in a single function that acquires new data from the Codeup database and save it as well as any helper functions in your `acquire.py` file.</font>**\n",
    "\n",
    "```python\n",
    "# Create helper function to get the necessary connection url.\n",
    "def get_connection(db, user=user, host=host, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "\n",
    "# Use the above helper function and a sql query in a single function.\n",
    "def get_data():\n",
    "    sql_query = 'write your sql query here; test it in Sequel Pro first!'\n",
    "    return pd.read_sql(sql_query, get_connection('database_name'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our helper function to get the connection url for our database.\n",
    "\n",
    "def get_connection(db, user=user, host=host, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple query, but they can get much more complicated depending on what we need.\n",
    "\n",
    "sql_query = 'SELECT * FROM passengers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our acquire function that uses our helper function.\n",
    "\n",
    "def new_titanic_data():\n",
    "    return pd.read_sql(sql_query, get_connection('titanic_db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our function to read titanic data into a DataFrame.\n",
    "\n",
    "titanic_df = get_titanic_data()\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Files\n",
    "\n",
    "- Create your DataFrame from a csv file.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('file_path/file_name.csv')\n",
    "```\n",
    "- Create your DataFrame from an AWS S3 file.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('https://s3.amazonaws.com/bucket_and_or_file_name.csv')\n",
    "```\n",
    "\n",
    "- Create your DataFrame from a Google sheet using its Share url.\n",
    "\n",
    "```python\n",
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'\n",
    "```  \n",
    "\n",
    "```python\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "```\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(csv_export_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign our Google Sheet share url to a variable.\n",
    "\n",
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the replace method to modify our url, so we can export it.\n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read_csv() method to create our DataFrame.\n",
    "\n",
    "df_googlesheet = pd.read_csv(csv_export_url)\n",
    "df_googlesheet.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Your Clipboard\n",
    "\n",
    "Read copy-pasted tabular data and parse it into a DataFrame.\n",
    "\n",
    "```python\n",
    "pd.read_clipboard(header=None, names=colums)\n",
    "```\n",
    "\n",
    "[Here's](https://towardsdatascience.com/pandas-hacks-read-clipboard-94a05c031382) a short and sweet article that explains it all nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the read_clipboard() method here using the article.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From an Excel Sheet\n",
    "\n",
    "```python\n",
    "pd.read_excel('your_excel_file_name.xlsx', sheet_name='your_table_name', usecols=['this_one', 'this_one'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in one sheet from my_telco_churn excel workbook.\n",
    "\n",
    "customers_df = pd.read_excel('my_telco_churn.xlsx', sheet_name='Table2_CustDetails')\n",
    "customers_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Pydataset\n",
    "\n",
    "Create your DataFrame using Pydataset and Read the Doc.\n",
    "\n",
    "```python\n",
    "from pydataset import data\n",
    "\n",
    "data('iris', show_doc=True)\n",
    "\n",
    "df_iris = data('iris')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame using pydataset 'iris'\n",
    "\n",
    "df_iris = data('iris')\n",
    "df_iris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Seaborn Datasets. This one has nice column names! :)\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove limegreen; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Data Acquisition\n",
    "\n",
    "-  The process of acquiring, preparing, exploring, modeling, and evaluating data is called the Data Science Pipeline.\n",
    "\n",
    "\n",
    "- As we go through the pipeline, our goal is to end each stage with functions that automate the process and can feed into the next stage, making our work faster and more importantly, repeatable.\n",
    "\n",
    "\n",
    "- We store our functions from each stage in modules, `acquire.py`, `prepare.py`, etc., and import them for use in our notebooks. All of the helper and main functions are stored in the `.py` file or module.\n",
    "\n",
    "\n",
    "- Ideally, upon completing the entire process, we should be able to use all of our functions, from each stage, to create one pipeline function that can reproduce our entire process from aquisition to evaluation.\n",
    "\n",
    "\n",
    "- If our goal is to acquire the titanic data from the Codeup database, both of the funtions below would be stored in an `acquire.py` file and imported into our notebook for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove limegreen; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's steal our code from above and throw it into a function.\n",
    "\n",
    "def get_connection(db, user=user, host=host, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_data():\n",
    "    '''\n",
    "    This function reads in the titanic data from the Codeup db\n",
    "    and returns a pandas DataFrame with all columns.\n",
    "    '''\n",
    "    sql_query = 'SELECT * FROM passengers'\n",
    "    return pd.read_sql(sql_query, get_connection('titanic_db'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove limegreen; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching Data\n",
    "\n",
    "**<font color=green>Save time by saving your data to a csv file for future use.</font>**\n",
    "\n",
    "- Caching or storing data you've retrieved from a database or website makes accessing it later much faster. Basically, cached data reduces load times.\n",
    "\n",
    "- We can design our acquire functions to get our data for us faster by reading in a csv file, if one exists, and if not, acquiring our data and creating a csv file for later use.\n",
    "\n",
    "- The `os.path.isfile()` method in Python is used to check whether a specified path is an existing file or not. It returns a boolean value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove limegreen; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to see if a file names 'titanic_df.csv' exists in this directory.\n",
    "\n",
    "os.path.isfile('titanic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write our 'titanic_df' DataFrame to a csv file.\n",
    "\n",
    "titanic_df.to_csv('titanic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check again...\n",
    "\n",
    "os.path.isfile('titanic_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use this concept to write a new function that allows us to hit the Codeup database, write the data to a csv file for later use, and read the data into a pandas DataFrame the next time we call the function and the csv file exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our first helper function that's used below.\n",
    "\n",
    "def get_connection(db, user=user, host=host, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's modify our function from above to cache our data.\n",
    "\n",
    "def new_titanic_data():\n",
    "    # Create SQL query.\n",
    "    sql_query = 'SELECT * FROM passengers'\n",
    "    \n",
    "    # Read in DataFrame from Codeup db.\n",
    "    df = pd.read_sql(sql_query, get_connection('titanic_db'))\n",
    "    \n",
    "    # Write DataFrame to a csv file.\n",
    "    df.to_csv('titanic_df.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_data(cached=False):\n",
    "    '''\n",
    "    This function reads in titanic data from Codeup database if cached == False\n",
    "    or if cached == True reads in titanic df from a csv file, returns df\n",
    "    '''\n",
    "    if cached == False or os.path.isfile('titanic_df.csv') == False:\n",
    "        df = new_titanic_data()\n",
    "    else:\n",
    "        df = pd.read_csv('titanic_df.csv', index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_titanic_data(cached=True)\n",
    "df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
